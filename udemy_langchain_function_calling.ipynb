{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mshinohar/langchain-book/blob/main/udemy_langchain_function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Udemy講座「LangChainによる大規模言語モデル（LLM）アプリケーション開発入門」セクション「（アップデート）OpenAI の Chat API の Function calling 機能について」のソースコード"
      ],
      "metadata": {
        "id": "gPaBhIsrXpyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Function calling の基本"
      ],
      "metadata": {
        "id": "9GnZluClXy2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ],
      "metadata": {
        "id": "6Q8D-SSuYDsK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "flvxPodovGlF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yUmuS7FiXk1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be35f194-3ef0-45d4-e601-9564bc0df552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --quiet langchain==0.0.229 openai==0.27.8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下はOpenAIの公式のサンプルコードをもとに一部変更（printの追加など）したソースコードです。\n",
        "\n",
        "参考：https://platform.openai.com/docs/guides/gpt/function-calling"
      ],
      "metadata": {
        "id": "TfUeweMPZhiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "\n",
        "\n",
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"72\",\n",
        "        \"unit\": unit,\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)\n",
        "\n",
        "\n",
        "def run_conversation():\n",
        "    # Step 1: send the conversation and available functions to GPT\n",
        "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}]\n",
        "    functions = [\n",
        "        {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-0613\",\n",
        "        messages=messages,\n",
        "        functions=functions,\n",
        "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
        "    )\n",
        "    print(\"=== first response ===\")\n",
        "    print(response)\n",
        "    response_message = response[\"choices\"][0][\"message\"]\n",
        "\n",
        "    # Step 2: check if GPT wanted to call a function\n",
        "    if response_message.get(\"function_call\"):\n",
        "        # Step 3: call the function\n",
        "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "        available_functions = {\n",
        "            \"get_current_weather\": get_current_weather,\n",
        "        }  # only one function in this example, but you can have multiple\n",
        "        function_name = response_message[\"function_call\"][\"name\"]\n",
        "        fuction_to_call = available_functions[function_name]\n",
        "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
        "        function_response = fuction_to_call(\n",
        "            location=function_args.get(\"location\"),\n",
        "            unit=function_args.get(\"unit\"),\n",
        "        )\n",
        "        print(\"=== python function output ===\")\n",
        "        print(function_response)\n",
        "\n",
        "        # Step 4: send the info on the function call and function response to GPT\n",
        "        messages.append(response_message)  # extend conversation with assistant's reply\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": \"function\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )  # extend conversation with function response\n",
        "        print(\"=== second request messages ===\")\n",
        "        print(json.dumps(messages, indent=2))\n",
        "        second_response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-0613\",\n",
        "            messages=messages,\n",
        "        )  # get a new response from GPT where it can see the function response\n",
        "        print(\"=== second response ===\")\n",
        "        print(second_response)\n",
        "\n",
        "\n",
        "run_conversation()"
      ],
      "metadata": {
        "id": "HtpIkTOoYQyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21bba699-1e00-4aa3-c89f-0ee33996234e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== first response ===\n",
            "{\n",
            "  \"id\": \"chatcmpl-8XSDekccDiZPWWvcAr7lj8o8EWq6I\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1702983990,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": null,\n",
            "        \"function_call\": {\n",
            "          \"name\": \"get_current_weather\",\n",
            "          \"arguments\": \"{\\n  \\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n",
            "        }\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"function_call\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 82,\n",
            "    \"completion_tokens\": 18,\n",
            "    \"total_tokens\": 100\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n",
            "=== python function output ===\n",
            "{\"location\": \"Boston, MA\", \"temperature\": \"72\", \"unit\": null, \"forecast\": [\"sunny\", \"windy\"]}\n",
            "=== second request messages ===\n",
            "[\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": \"What's the weather like in Boston?\"\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": null,\n",
            "    \"function_call\": {\n",
            "      \"name\": \"get_current_weather\",\n",
            "      \"arguments\": \"{\\n  \\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"role\": \"function\",\n",
            "    \"name\": \"get_current_weather\",\n",
            "    \"content\": \"{\\\"location\\\": \\\"Boston, MA\\\", \\\"temperature\\\": \\\"72\\\", \\\"unit\\\": null, \\\"forecast\\\": [\\\"sunny\\\", \\\"windy\\\"]}\"\n",
            "  }\n",
            "]\n",
            "=== second response ===\n",
            "{\n",
            "  \"id\": \"chatcmpl-8XSDf8Tp0Ky0Dx3KFWtDh8nrTHxey\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1702983991,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"The weather in Boston is currently sunny and windy, with a temperature of 72 degrees.\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 72,\n",
            "    \"completion_tokens\": 18,\n",
            "    \"total_tokens\": 90\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Function calling を使った LangChain の「OpenAI Functions Agent」"
      ],
      "metadata": {
        "id": "cYVllqZpX4SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "import openai\n",
        "from langchain.agents import AgentType, initialize_agent, Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"72\",\n",
        "        \"unit\": unit,\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"get_current_weather\",\n",
        "        func=get_current_weather,\n",
        "        description=\"Get the current weather in a given location\"\n",
        "    )\n",
        "]\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "agent = initialize_agent(tools, chat, agent=AgentType.OPENAI_FUNCTIONS)\n",
        "\n",
        "result = agent.run(\"What's the weather like in Boston?\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "YeTACULxd0Za",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b693528-d862-49b5-cc89-be5c3406862c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current weather in Boston is 72 degrees Fahrenheit. It is sunny and windy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\", \"llm-math\"], llm=chat)\n",
        "agent = initialize_agent(tools, chat, agent=AgentType.OPENAI_FUNCTIONS)\n",
        "\n",
        "result = agent.run(\"Show files in ./sample_data directory.\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "enGZhQ0IX8oJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d54cc8-44a9-48c3-e122-ac251d18e7cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the files in the `./sample_data` directory:\n",
            "\n",
            "1. anscombe.json\n",
            "2. california_housing_test.csv\n",
            "3. california_housing_train.csv\n",
            "4. mnist_test.csv\n",
            "5. mnist_train_small.csv\n",
            "6. README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Function calling を応用した Extraction と Tagging"
      ],
      "metadata": {
        "id": "JUKtMHXMX9F4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下はLangChainの公式ドキュメントのこちらのページを参考にしたサンプルコードです。\n",
        "\n",
        "https://python.langchain.com/docs/modules/chains/additional/extraction\n",
        "\n",
        "※ LangChainの公式ドキュメントは高い頻度でリンク切れになります。もしリンク切れになっている場合は、LangChainのドキュメントで「Extraction」と検索してみてください。"
      ],
      "metadata": {
        "id": "PxQdhrhmmt9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "import openai\n",
        "import langchain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import create_extraction_chain, create_extraction_chain_pydantic\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "openai.log = \"debug\"\n",
        "langchain.verbose = True\n",
        "\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"person_name\": {\"type\": \"string\"},\n",
        "        \"person_height\": {\"type\": \"integer\"},\n",
        "        \"person_hair_color\": {\"type\": \"string\"},\n",
        "        \"dog_name\": {\"type\": \"string\"},\n",
        "        \"dog_breed\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"person_name\", \"person_height\"],\n",
        "}\n",
        "inp = \"\"\"\n",
        "Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
        "Alex's dog Frosty is a labrador and likes to play hide and seek.\n",
        "\"\"\"\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "chain = create_extraction_chain(schema, chat)\n",
        "\n",
        "result = chain.run(inp)\n",
        "print(f\"\"\"=== result ===\n",
        "{json.dumps(result, indent=2)}\n",
        "===\"\"\")"
      ],
      "metadata": {
        "id": "nhT9f_seX-8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412b6883-fea7-4975-e320-6f03ebaecde8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: Extract and save the relevant entities mentioned in the following passage together with their properties.\n",
            "\n",
            "Passage:\n",
            "\n",
            "Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
            "Alex's dog Frosty is a labrador and likes to play hide and seek.\n",
            "\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
            "api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Extract and save the relevant entities mentioned in the following passage together with their properties.\\\\n\\\\nPassage:\\\\n\\\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\\\nAlex\\'s dog Frosty is a labrador and likes to play hide and seek.\\\\n\\\\n\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"functions\": [{\"name\": \"information_extraction\", \"description\": \"Extracts the relevant information from the passage.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"info\": {\"type\": \"array\", \"items\": {\"type\": \"object\", \"properties\": {\"person_name\": {\"title\": \"person_name\", \"type\": \"string\"}, \"person_height\": {\"title\": \"person_height\", \"type\": \"integer\"}, \"person_hair_color\": {\"title\": \"person_hair_color\", \"type\": \"string\"}, \"dog_name\": {\"title\": \"dog_name\", \"type\": \"string\"}, \"dog_breed\": {\"title\": \"dog_breed\", \"type\": \"string\"}}, \"required\": [\"person_name\", \"person_height\"]}}}, \"required\": [\"info\"]}}], \"function_call\": {\"name\": \"information_extraction\"}}' message='Post details'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "=== result ===\n",
            "[\n",
            "  {\n",
            "    \"person_name\": \"Alex\",\n",
            "    \"person_height\": 5,\n",
            "    \"person_hair_color\": \"blonde\",\n",
            "    \"dog_name\": \"Frosty\",\n",
            "    \"dog_breed\": \"labrador\"\n",
            "  },\n",
            "  {\n",
            "    \"person_name\": \"Claudia\",\n",
            "    \"person_height\": 6,\n",
            "    \"person_hair_color\": \"brunette\"\n",
            "  }\n",
            "]\n",
            "===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3847 request_id=c1bfd066920b12da80f4bb8d0fb6042b response_code=200\n",
            "body='{\\n  \"id\": \"chatcmpl-8XSGnPc9UplHqkG2yCQ1lGNyWQ2KX\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1702984185,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": null,\\n        \"function_call\": {\\n          \"name\": \"information_extraction\",\\n          \"arguments\": \"{\\\\n  \\\\\"info\\\\\": [\\\\n    {\\\\n      \\\\\"person_name\\\\\": \\\\\"Alex\\\\\",\\\\n      \\\\\"person_height\\\\\": 5,\\\\n      \\\\\"person_hair_color\\\\\": \\\\\"blonde\\\\\",\\\\n      \\\\\"dog_name\\\\\": \\\\\"Frosty\\\\\",\\\\n      \\\\\"dog_breed\\\\\": \\\\\"labrador\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\"person_name\\\\\": \\\\\"Claudia\\\\\",\\\\n      \\\\\"person_height\\\\\": 6,\\\\n      \\\\\"person_hair_color\\\\\": \\\\\"brunette\\\\\"\\\\n    }\\\\n  ]\\\\n}\"\\n        }\\n      },\\n      \"logprobs\": null,\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 154,\\n    \"completion_tokens\": 94,\\n    \"total_tokens\": 248\\n  },\\n  \"system_fingerprint\": null\\n}\\n' headers='{\\'Date\\': \\'Tue, 19 Dec 2023 11:09:49 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-nlomaspt3qpx4wffhp9qldqq\\', \\'openai-processing-ms\\': \\'3847\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-limit-tokens_usage_based\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'195\\', \\'x-ratelimit-remaining-tokens\\': \\'39907\\', \\'x-ratelimit-remaining-tokens_usage_based\\': \\'39907\\', \\'x-ratelimit-reset-requests\\': \\'34m48.89s\\', \\'x-ratelimit-reset-tokens\\': \\'139ms\\', \\'x-ratelimit-reset-tokens_usage_based\\': \\'139ms\\', \\'x-request-id\\': \\'c1bfd066920b12da80f4bb8d0fb6042b\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Set-Cookie\\': \\'__cf_bm=loncGfIaM0oYjnZHnvrVZYjhfQ_BFOSkrjOfE1VKrGU-1702984189-1-AUMjGqvrEoSaQvrE/ccNTry+/e0Jy3cgoboOTCEsmV3f+pzFKDpVQlwnsol6Qz+cVs3jDM1gRcC8Pqc6Q/Ue/Cw=; path=/; expires=Tue, 19-Dec-23 11:39:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=Pek9zaDiRtJI5oD_Rn9865s7isSas3dUwfjjvroDuEU-1702984189556-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'837f31f7fc1a6160-ORD\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下はLangChainの公式ドキュメントのこちらのページを参考にしたサンプルコードです。\n",
        "\n",
        "https://python.langchain.com/docs/modules/chains/additional/tagging\n",
        "\n",
        "※ LangChainの公式ドキュメントは高い頻度でリンク切れになります。もしリンク切れになっている場合は、LangChainのドキュメントで「Tagging」と検索してみてください。"
      ],
      "metadata": {
        "id": "y-pYlTwanQFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import create_tagging_chain, create_tagging_chain_pydantic\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "openai.log = \"debug\"\n",
        "langchain.verbose = True\n",
        "\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"sentiment\": {\"type\": \"string\"},\n",
        "        \"aggressiveness\": {\"type\": \"integer\"},\n",
        "        \"language\": {\"type\": \"string\"},\n",
        "    }\n",
        "}\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "chain = create_tagging_chain(schema, chat)\n",
        "\n",
        "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
        "\n",
        "result = chain.run(inp)\n",
        "print(f\"\"\"=== result ===\n",
        "{json.dumps(result, indent=2)}\n",
        "===\"\"\")"
      ],
      "metadata": {
        "id": "m0fhnhBIkuel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56940707-06a3-44f2-d535-43d6910ec8c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mHuman: Extract the desired information from the following passage.\n",
            "\n",
            "Passage:\n",
            "Estoy muy enojado con vos! Te voy a dar tu merecido!\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
            "api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Extract the desired information from the following passage.\\\\n\\\\nPassage:\\\\nEstoy muy enojado con vos! Te voy a dar tu merecido!\\\\n\"}], \"model\": \"gpt-3.5-turbo\", \"max_tokens\": null, \"stream\": false, \"n\": 1, \"temperature\": 0.0, \"functions\": [{\"name\": \"information_extraction\", \"description\": \"Extracts the relevant information from the passage.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"sentiment\": {\"title\": \"sentiment\", \"type\": \"string\"}, \"aggressiveness\": {\"title\": \"aggressiveness\", \"type\": \"integer\"}, \"language\": {\"title\": \"language\", \"type\": \"string\"}}, \"required\": []}}], \"function_call\": {\"name\": \"information_extraction\"}}' message='Post details'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "=== result ===\n",
            "{\n",
            "  \"sentiment\": \"enojado\",\n",
            "  \"aggressiveness\": 1,\n",
            "  \"language\": \"Spanish\"\n",
            "}\n",
            "===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1702 request_id=9c5cac23f65cf2778328f23b0cc5e4a3 response_code=200\n",
            "body='{\\n  \"id\": \"chatcmpl-8XSH38avAYyU8RDndAedJBP7b6nxw\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1702984201,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": null,\\n        \"function_call\": {\\n          \"name\": \"information_extraction\",\\n          \"arguments\": \"{\\\\n  \\\\\"sentiment\\\\\": \\\\\"enojado\\\\\",\\\\n  \\\\\"aggressiveness\\\\\": 1,\\\\n  \\\\\"language\\\\\": \\\\\"Spanish\\\\\"\\\\n}\"\\n        }\\n      },\\n      \"logprobs\": null,\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 95,\\n    \"completion_tokens\": 28,\\n    \"total_tokens\": 123\\n  },\\n  \"system_fingerprint\": null\\n}\\n' headers='{\\'Date\\': \\'Tue, 19 Dec 2023 11:10:02 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-nlomaspt3qpx4wffhp9qldqq\\', \\'openai-processing-ms\\': \\'1702\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'200\\', \\'x-ratelimit-limit-tokens\\': \\'40000\\', \\'x-ratelimit-limit-tokens_usage_based\\': \\'40000\\', \\'x-ratelimit-remaining-requests\\': \\'194\\', \\'x-ratelimit-remaining-tokens\\': \\'39952\\', \\'x-ratelimit-remaining-tokens_usage_based\\': \\'39952\\', \\'x-ratelimit-reset-requests\\': \\'41m45.972s\\', \\'x-ratelimit-reset-tokens\\': \\'72ms\\', \\'x-ratelimit-reset-tokens_usage_based\\': \\'72ms\\', \\'x-request-id\\': \\'9c5cac23f65cf2778328f23b0cc5e4a3\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'837f325529446160-ORD\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 1 度に複数の関数を実行できる LangChain の「OpenAI Multi Functions Agent」"
      ],
      "metadata": {
        "id": "86Brxh4OYAyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下はLangChainの公式ドキュメントのこちらのページを参考にしたサンプルコードです。\n",
        "\n",
        "https://python.langchain.com/docs/modules/agents/agent_types/openai_multi_functions_agent\n",
        "\n",
        "※ LangChainの公式ドキュメントは高い頻度でリンク切れになります。もしリンク切れになっている場合は、LangChainのドキュメントで「OpenAI Multi Functions Agent」などと検索してみてください。"
      ],
      "metadata": {
        "id": "v3A6uhLEnakx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# duckduckgo-searchのバージョン3.8.3は動作しなくなったため、バージョン4.1.0をインストールします\n",
        "\n",
        "!pip install --quiet duckduckgo-search==4.1.0"
      ],
      "metadata": {
        "id": "tzA7CDvMmHAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d361a4a-e3ed-4adc-8d66-0d0c97b16eaa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import openai\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "langchain.debug = True\n",
        "langchain.verbose = False\n",
        "openai.log = \"info\"\n",
        "\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "agent = initialize_agent(tools, chat, agent=AgentType.OPENAI_MULTI_FUNCTIONS)\n",
        "\n",
        "result = agent.run(\n",
        "    \"What is the weather in LA and SF?\"\n",
        ")\n",
        "print(f\"\"\"=== result ===\n",
        "{result}\n",
        "===\"\"\")"
      ],
      "metadata": {
        "id": "3ZSkY59CYBwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d98668-35c5-446c-edc4-3758ab6ee18e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"What is the weather in LA and SF?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful AI assistant.\\nHuman: What is the weather in LA and SF?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] [3.50s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": null,\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"function_call\": {\n",
            "                \"name\": \"tool_selection\",\n",
            "                \"arguments\": \"{\\n  \\\"actions\\\": [\\n    {\\n      \\\"action_name\\\": \\\"duckduckgo_search\\\",\\n      \\\"action\\\": {\\n        \\\"query\\\": \\\"weather in Los Angeles\\\"\\n      }\\n    },\\n    {\\n      \\\"action_name\\\": \\\"duckduckgo_search\\\",\\n      \\\"action\\\": {\\n        \\\"query\\\": \\\"weather in San Francisco\\\"\\n      }\\n    }\\n  ]\\n}\"\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 83,\n",
            "      \"completion_tokens\": 79,\n",
            "      \"total_tokens\": 162\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 3:tool:duckduckgo_search] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': 'weather in Los Angeles'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 3:tool:duckduckgo_search] [938.834ms] Exiting Tool run with output:\n",
            "\u001b[0m\"Current Conditions Radar Forecasts Rivers and Lakes Climate and Past Weather Local Programs Weather Outlook: Offshore Winds to Rainfall Show Caption Click a location below for detailed forecast. Last Map Update: Thu, Dec. 14, 2023 at 11:58:24 pm PST Watches, Warnings & Advisories Zoom Out Small Craft Advisory Find the current weather conditions, forecast, radar, and historical data for Los Angeles, CA. Learn about the weather history, news, and stories from the Los Angeles area and beyond. Get the current weather and forecast for Los Angeles, California, United States, with temperature, wind speed, precipitation, sea/surf conditions and more. See the hourly and daily outlook for the next 10 days, as well as the historical data and maps. Find the current and forecast weather conditions for Los Angeles, United States of America, including temperature, wind, visibility, UV and precipitation. See the seven-day forecast for each day, with weather symbols and temperature units. Hourly Trending news Temperature map Weather Radar Satellites Models Today Dec. 16 79° / 50° 7 - 13 mph Tomorrow Dec. 17 77° / 49° 8 - 16 mph Monday Dec. 18 50% 0.004 in 68° / 57° 7 - 11 mph Tuesday Dec. 19 80% 0.071 in 66° / 56° 6 - 11 mph Wednesday Dec. 20 80% 0.965 in 63° / 55° 14 - 25 mph Thursday Dec. 21 80% 0.657 in 61° / 50° 12 - 24 mph\"\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:duckduckgo_search] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': 'weather in San Francisco'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:duckduckgo_search] [979.519ms] Exiting Tool run with output:\n",
            "\u001b[0m\"58° | 44° 58 °F like 58° Partly Cloudy N 0 Today's temperature is forecast to be NEARLY THE SAME as yesterday. Radar Satellite WunderMap |Nexrad Forecasts Rivers and Lakes Climate and Past Weather Local Programs Expected Rain Totals Show Caption Click a location below for detailed forecast. Last Map Update: Sun, Dec. 17, 2023 at 5:10:32 am PST Watches, Warnings & Advisories Zoom Out Gale Warning Small Craft Advisory Wind Advisory Gale Watch Marine Weather Statement Get the current weather and forecast for San Francisco, California, United States, with temperature, wind speed, precipitation, sea/surf conditions and more. See the hourly and daily outlook for the next 10 days, as well as the historical data and maps. Current Conditions Radar Forecasts Rivers and Lakes Climate and Past Weather Local Programs Expected Rain Totals Show Caption Click a location below for detailed forecast. Last Map Update: Sat, Dec. 16, 2023 at 3:15:30 am PST Watches, Warnings & Advisories Zoom Out Small Craft Advisory Gale Watch Find the current and forecast weather conditions for San Francisco, United States of America, including temperature, wind, visibility, humidity and UV index. See the daily and weekly forecast for the next 10 days, with weather symbols and UV information.\"\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful AI assistant.\\nHuman: What is the weather in LA and SF?\\nAI: {'name': 'tool_selection', 'arguments': '{\\\\n  \\\"actions\\\": [\\\\n    {\\\\n      \\\"action_name\\\": \\\"duckduckgo_search\\\",\\\\n      \\\"action\\\": {\\\\n        \\\"query\\\": \\\"weather in Los Angeles\\\"\\\\n      }\\\\n    },\\\\n    {\\\\n      \\\"action_name\\\": \\\"duckduckgo_search\\\",\\\\n      \\\"action\\\": {\\\\n        \\\"query\\\": \\\"weather in San Francisco\\\"\\\\n      }\\\\n    }\\\\n  ]\\\\n}'}\\nFunction: Current Conditions Radar Forecasts Rivers and Lakes Climate and Past Weather Local Programs Weather Outlook: Offshore Winds to Rainfall Show Caption Click a location below for detailed forecast. Last Map Update: Thu, Dec. 14, 2023 at 11:58:24 pm PST Watches, Warnings & Advisories Zoom Out Small Craft Advisory Find the current weather conditions, forecast, radar, and historical data for Los Angeles, CA. Learn about the weather history, news, and stories from the Los Angeles area and beyond. Get the current weather and forecast for Los Angeles, California, United States, with temperature, wind speed, precipitation, sea/surf conditions and more. See the hourly and daily outlook for the next 10 days, as well as the historical data and maps. Find the current and forecast weather conditions for Los Angeles, United States of America, including temperature, wind, visibility, UV and precipitation. See the seven-day forecast for each day, with weather symbols and temperature units. Hourly Trending news Temperature map Weather Radar Satellites Models Today Dec. 16 79° / 50° 7 - 13 mph Tomorrow Dec. 17 77° / 49° 8 - 16 mph Monday Dec. 18 50% 0.004 in 68° / 57° 7 - 11 mph Tuesday Dec. 19 80% 0.071 in 66° / 56° 6 - 11 mph Wednesday Dec. 20 80% 0.965 in 63° / 55° 14 - 25 mph Thursday Dec. 21 80% 0.657 in 61° / 50° 12 - 24 mph\\nAI: {'name': 'tool_selection', 'arguments': '{\\\\n  \\\"actions\\\": [\\\\n    {\\\\n      \\\"action_name\\\": \\\"duckduckgo_search\\\",\\\\n      \\\"action\\\": {\\\\n        \\\"query\\\": \\\"weather in Los Angeles\\\"\\\\n      }\\\\n    },\\\\n    {\\\\n      \\\"action_name\\\": \\\"duckduckgo_search\\\",\\\\n      \\\"action\\\": {\\\\n        \\\"query\\\": \\\"weather in San Francisco\\\"\\\\n      }\\\\n    }\\\\n  ]\\\\n}'}\\nFunction: 58° | 44° 58 °F like 58° Partly Cloudy N 0 Today's temperature is forecast to be NEARLY THE SAME as yesterday. Radar Satellite WunderMap |Nexrad Forecasts Rivers and Lakes Climate and Past Weather Local Programs Expected Rain Totals Show Caption Click a location below for detailed forecast. Last Map Update: Sun, Dec. 17, 2023 at 5:10:32 am PST Watches, Warnings & Advisories Zoom Out Gale Warning Small Craft Advisory Wind Advisory Gale Watch Marine Weather Statement Get the current weather and forecast for San Francisco, California, United States, with temperature, wind speed, precipitation, sea/surf conditions and more. See the hourly and daily outlook for the next 10 days, as well as the historical data and maps. Current Conditions Radar Forecasts Rivers and Lakes Climate and Past Weather Local Programs Expected Rain Totals Show Caption Click a location below for detailed forecast. Last Map Update: Sat, Dec. 16, 2023 at 3:15:30 am PST Watches, Warnings & Advisories Zoom Out Small Craft Advisory Gale Watch Find the current and forecast weather conditions for San Francisco, United States of America, including temperature, wind, visibility, humidity and UV index. See the daily and weekly forecast for the next 10 days, with weather symbols and UV information.\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:llm:ChatOpenAI] [3.14s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"The current weather in Los Angeles is 58°F with partly cloudy skies. The temperature is expected to remain nearly the same throughout the day.\\n\\nIn San Francisco, the current temperature is also 58°F. The weather conditions include partly cloudy skies.\\n\\nPlease note that weather conditions can change rapidly, so it's always a good idea to check for the latest updates.\",\n",
            "        \"generation_info\": null,\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"The current weather in Los Angeles is 58°F with partly cloudy skies. The temperature is expected to remain nearly the same throughout the day.\\n\\nIn San Francisco, the current temperature is also 58°F. The weather conditions include partly cloudy skies.\\n\\nPlease note that weather conditions can change rapidly, so it's always a good idea to check for the latest updates.\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 892,\n",
            "      \"completion_tokens\": 73,\n",
            "      \"total_tokens\": 965\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [8.58s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"The current weather in Los Angeles is 58°F with partly cloudy skies. The temperature is expected to remain nearly the same throughout the day.\\n\\nIn San Francisco, the current temperature is also 58°F. The weather conditions include partly cloudy skies.\\n\\nPlease note that weather conditions can change rapidly, so it's always a good idea to check for the latest updates.\"\n",
            "}\n",
            "=== result ===\n",
            "The current weather in Los Angeles is 58°F with partly cloudy skies. The temperature is expected to remain nearly the same throughout the day.\n",
            "\n",
            "In San Francisco, the current temperature is also 58°F. The weather conditions include partly cloudy skies.\n",
            "\n",
            "Please note that weather conditions can change rapidly, so it's always a good idea to check for the latest updates.\n",
            "===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QAxTRphfmFEb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}