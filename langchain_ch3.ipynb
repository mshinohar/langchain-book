{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mshinohar/langchain-book/blob/main/langchain_ch3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzrWQTLn70Ra"
      },
      "source": [
        "# ChatGPTをAPIから利用するために"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKSpjd8v8A9H"
      },
      "source": [
        "## 3-3 入出力の長さの制限や課金に影響する「トークン」"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6fSq7bc8DES"
      },
      "source": [
        "### Tokenizerとtiktokenの紹介"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MPred-0se6z",
        "outputId": "3ad25739-4fad-4a9d-bd7d-795c53b2f66d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWdpn2pw8NGp",
        "outputId": "30ecc774-817d-4e0d-90ad-a6e71132d8cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"LLMを使ってクールなものを作るのは簡単だが、プロダクションで使えるものを作るのは非常に難しい。\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNeWKD2O8JB5"
      },
      "source": [
        "### 日本語のトークン数について"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwIhYtWcshOY",
        "outputId": "57e95502-c01e-4ae8-cbcc-bd71e18c1be3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n"
          ]
        }
      ],
      "source": [
        "text = \"It’s easy to make something cool with LLMs, but very hard to make something production-ready with them.\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P56iAwzT8Xmq"
      },
      "source": [
        "## 3-4 Chat Completions APIにふれる環境準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIZY8RE38cUC"
      },
      "source": [
        "### Google Colabのノートブック作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4TeCLj3Qe5r"
      },
      "outputs": [],
      "source": [
        "print(\"Hello World\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjYCIb2Q8fbe"
      },
      "source": [
        "### OpenAIのAPIキーの準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your api key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0l8ptIe8iH5"
      },
      "source": [
        "## 3-5 Chat Completions APIをさわってみる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p9pLImp8kQ9"
      },
      "source": [
        "### OpenAIのライブラリ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R8jT7MNRC9t",
        "outputId": "c0896e4f-3643-4b99-f175-4a4f10ea7d69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTD-Xe9G8r6w"
      },
      "source": [
        "### Chat Completions APIの呼び出し"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHJUSC61Wg_y",
        "outputId": "2855e084-0060-4a79-9821-dfd610ce0f72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8DS3Btm4aX3NJwTPmvoIFiuCEyxNC\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1698216781,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Hello John! How can I assist you today?\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 23,\n",
            "    \"completion_tokens\": 10,\n",
            "    \"total_tokens\": 33\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello! I'm John.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2THywRt8t0F"
      },
      "source": [
        "### 会話履歴を踏まえた応答を得る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk5Cc6rtWtub",
        "outputId": "98fa27fa-3e03-4890-ec01-552214e099d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-8DS4DPLBqORiERPse6Y0jQo96ArX7 at 0x7b460e8178d0> JSON: {\n",
              "  \"id\": \"chatcmpl-8DS4DPLBqORiERPse6Y0jQo96ArX7\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1698216845,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"Yes, you mentioned your name is John. How can I assist you further, John?\"\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 47,\n",
              "    \"completion_tokens\": 18,\n",
              "    \"total_tokens\": 65\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello! I'm John.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Hello John! How can I assist you today?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do you know my name?\"}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKRqvj0u8xWL"
      },
      "source": [
        "### ストリーミングで応答を得る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7J2Gq9PYPBA",
        "outputId": "4daa6ca1-e3f7-4429-a6c7-95287f9f3bf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hello\n",
            " John\n",
            "!\n",
            " How\n",
            " can\n",
            " I\n",
            " assist\n",
            " you\n",
            " today\n",
            "?\n"
          ]
        }
      ],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello! I'm John.\"}\n",
        "  ],\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "  choice = chunk[\"choices\"][0]\n",
        "  if choice[\"finish_reason\"] is None:\n",
        "    print(choice[\"delta\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqKaUhJ08zQ1"
      },
      "source": [
        "### （コラム）Completions API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD6Z-BZsCF3P",
        "outputId": "4a337771-a79f-4d1b-e103-fad5f30a655d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8DS5cPHA1zFTnvJ0XnuFreca3ILFq\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1698216932,\n",
            "  \"model\": \"text-davinci-003\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \"\\n\\nNice to meet you John! My name is Mary.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 6,\n",
            "    \"completion_tokens\": 13,\n",
            "    \"total_tokens\": 19\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=\"Hello! I'm John.\"\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKiq30SODvUP",
        "outputId": "78f5f810-03de-47b5-ad95-2a952d0557e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8DS9ZWoIJpbeS41xF5N2UppmfBgIt\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1698217177,\n",
            "  \"model\": \"text-davinci-003\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \" No, I don't know your name.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 31,\n",
            "    \"completion_tokens\": 9,\n",
            "    \"total_tokens\": 40\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"Human: Hello! I'm John.\n",
        "AI: Nice to meet you, John!\n",
        "Human: Do you know my name?\n",
        "AI: \"\"\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrlT300r83MS"
      },
      "source": [
        "## 3-6 Function calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwG5cpzg85Vn"
      },
      "source": [
        "### Function callingのサンプルコード\n",
        "\n",
        "[OpenAI の公式ドキュメント](https://platform.openai.com/docs/guides/gpt/function-calling) をもとに一部改変したコードです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K97Pbcw3bly8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def get_current_weather(location, unit=\"celsius\"):\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"25\",\n",
        "        \"unit\": \"celsius\",\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgIGMKtBgeGj"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    {\n",
        "        \"name\": \"get_current_weather\",\n",
        "        \"description\": \"Get the current weather in a given location\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city and state, e.g. Tokyo\",\n",
        "                },\n",
        "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "            },\n",
        "            \"required\": [\"location\"],\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO-VYo7tghih",
        "outputId": "c465bb2d-a21d-4db5-fdc0-5617d7a011e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8DSCnWGKONFZOBMYWPjsh2XTVXnTF\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1698217377,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": null,\n",
            "        \"function_call\": {\n",
            "          \"name\": \"get_current_weather\",\n",
            "          \"arguments\": \"{\\n  \\\"location\\\": \\\"Tokyo\\\",\\n  \\\"unit\\\": \\\"celsius\\\"\\n}\"\n",
            "        }\n",
            "      },\n",
            "      \"finish_reason\": \"function_call\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 79,\n",
            "    \"completion_tokens\": 25,\n",
            "    \"total_tokens\": 104\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages=messages,\n",
        "    functions=functions\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7LcVydmhlp0",
        "outputId": "bfe5d371-ed4e-4d5b-cf97-38051dc3fde4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"location\": \"Tokyo\", \"temperature\": \"25\", \"unit\": \"celsius\", \"forecast\": [\"sunny\", \"windy\"]}\n"
          ]
        }
      ],
      "source": [
        "response_message = response[\"choices\"][0][\"message\"]\n",
        "\n",
        "available_functions = {\n",
        "    \"get_current_weather\": get_current_weather,\n",
        "}\n",
        "function_name = response_message[\"function_call\"][\"name\"]\n",
        "fuction_to_call = available_functions[function_name]\n",
        "function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
        "\n",
        "function_response = fuction_to_call(\n",
        "    location=function_args.get(\"location\"),\n",
        "    unit=function_args.get(\"unit\"),\n",
        ")\n",
        "\n",
        "print(function_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe80yJNwjEJy"
      },
      "outputs": [],
      "source": [
        "messages.append(response_message)\n",
        "messages.append(\n",
        "    {\n",
        "        \"role\": \"function\",\n",
        "        \"name\": function_name,\n",
        "        \"content\": function_response,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9QBhpRtgtSW",
        "outputId": "b77d1506-a09a-4065-c8db-43795eea9d89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8DSFDe3nmBYZpUMkxIatKKMJHGwmA\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1698217527,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"The current weather in Tokyo is sunny and windy with a temperature of 25\\u00b0C.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 80,\n",
            "    \"completion_tokens\": 17,\n",
            "    \"total_tokens\": 97\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "second_response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "print(second_response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHa6kbZHpwRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}