{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mshinohar/langchain-book/blob/main/udemy_langchain_LCEL_copy_Ch14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ch14 LCEL\n",
        "- Udemy講座「LangChainによるLLM App開発入門」セクション\n",
        "- 「（アップデート）LangChain Expression Language （LCEL）」のソースコード"
      ],
      "metadata": {
        "id": "T9zLNoFZNM9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain Expression Language （LCEL）の概要と実装例"
      ],
      "metadata": {
        "id": "9Qp9b7liNVfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "Ro-6OVC6NKqd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain==0.0.329 openai==0.28.1"
      ],
      "metadata": {
        "id": "qLw6AV0tO6cQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c978822e-2b9a-4c10-c824-c12a9792a471"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# PromptTemplateを準備\n",
        "prompt = PromptTemplate.from_template(\"\"\"料理のレシピを考えてください。\n",
        "\n",
        "料理名: {dish}\"\"\")\n",
        "\n",
        "# LLMを準備\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# Chainを作成\n",
        "chain = prompt | llm\n",
        "\n",
        "# Chainを作成する処理は、LCEL以前は以下のように書いていました。\n",
        "# chain = LLMChain(llm=chat, prompt=prompt)\n",
        "\n",
        "result = chain.invoke({\"dish\": \"カレー\"})\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "_BNi9JXkNY0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c0d49d-afa4-425f-9ce8-851f15f41379"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "材料:\n",
            "- 400gの鶏肉（もも肉や胸肉など、お好みの部位）\n",
            "- 2個の玉ねぎ\n",
            "- 2個のにんじん\n",
            "- 2個のじゃがいも\n",
            "- 2個のトマト\n",
            "- 3つのにんにくのかけら\n",
            "- 1つの生姜のかけら\n",
            "- 2つのカレールウ（お好みの辛さ）\n",
            "- 2カップの水\n",
            "- 2つのカレーパウダー\n",
            "- 2つのターメリックパウダー\n",
            "- 2つのコリアンダーパウダー\n",
            "- 2つのクミンパウダー\n",
            "- 2つのパプリカパウダー\n",
            "- 2つの塩\n",
            "- 2つの砂糖\n",
            "- 2つの植物油\n",
            "\n",
            "手順:\n",
            "1. 鶏肉を食べやすい大きさに切り、玉ねぎ、にんじん、じゃがいも、トマトもそれぞれ適切な大きさに切る。\n",
            "2. 鍋に植物油を熱し、にんにくと生姜を加えて香りが立つまで炒める。\n",
            "3. 鶏肉を加えて全体が白くなるまで炒める。\n",
            "4. 野菜を加えて炒め、野菜が少し柔らかくなるまで続ける。\n",
            "5. カレールウを加えてよく混ぜ、香りが立つまで炒める。\n",
            "6. 水を加え、煮立つまで火にかける。\n",
            "7. カレーパウダー、ターメリックパウダー、コリアンダーパウダー、クミンパウダー、パプリカパウダー、塩、砂糖を加えてよく混ぜる。\n",
            "8. 中火で約30分間煮込む。必要に応じて水を追加する。\n",
            "9. カレーがとろみがついて野菜が柔らかくなったら、完成です。\n",
            "10. ご飯やナンと一緒にお召し上がりください。お好みでコリアンダーの葉やライムをトッピングしても美味しいです。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# OutputParserを準備\n",
        "class Recipe(BaseModel):\n",
        "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
        "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
        "\n",
        "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
        "\n",
        "# PromptTemplateを準備\n",
        "prompt = PromptTemplate.from_template(\"\"\"料理のレシピを考えてください。\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "料理名: {dish}\"\"\", partial_variables = {\"format_instructions\": output_parser.get_format_instructions()})\n",
        "\n",
        "# LLMを準備\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# Chainを作成\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# Chainを実行\n",
        "result = chain.invoke({\"dish\": \"カレー\"})\n",
        "print(type(result))\n",
        "print(result)"
      ],
      "metadata": {
        "id": "EZc8TPycQjrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b60a6a-f82c-4dd9-e48f-9bf4ba06277b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Recipe'>\n",
            "ingredients=['玉ねぎ', 'にんじん', 'じゃがいも', '牛肉', 'カレールー', '水'] steps=['玉ねぎ、にんじん、じゃがいもを切ります。', '牛肉を炒めます。', '野菜を加えて炒めます。', '水を加えて煮込みます。', 'カレールーを加えて溶かします。', '煮込んで完成です。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rorm7J63RWR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}